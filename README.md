# Pre-training-with-Augmentation-Data-in-Deep-Learning-Model



본 프로젝트는 고차원 데이터에서 전처리 방식에 따라 분석 결과가 달라지는 문제를 해결하기 위해
표준화된 데이터 처리 기준과 재현 가능한 처리 환경을 구축하는 것을 목표로 합니다.

모델 성능 향상이 아니라,
**동일한 데이터는 항상 동일한 결과가 나오도록 만드는 데이터 처리 기준 설계**에 초점을 둡니다.

---

| 항목 | 내용 |
|------|------|
| 데이터 | TCGA (공개 데이터) — 1,018명 × 19,977 변수 |
| 기간 | 2020.12 ~ 2021.07 |
| 성과 | 한국정보과학회 2021 학술대회 논문 게재 |

---

##  문제 정의

1,018개 샘플과 19,977개 변수로 구성된 고차원 의료 데이터는 전처리 순서, 스케일링 방식, 검증 방법에 따라 결과가 크게 달라졌습니다.
처리 기준이 없을 경우 다음 문제가 발생했습니다.

- 실험마다 결과가 달라짐
- 모델 성능 비교 불가능
- 분석 결과 해석 기준 불일치
- 실험 재현 어려움

따라서 본 프로젝트는 이를 모델 문제가 아닌 **데이터 신뢰성 문제**로 정의했습니다.

---

## 🎯 목표

- 전처리 기준 정의 및 고정
- 처리 순서 표준화
- 실험 결과 변동 제거
- 재현 가능한 분석 환경 구축
- 비교 가능한 실험 결과 확보

---

## 데이터 처리 기준 설계

### 1. 스케일링 기준 통일

- log2 변환 적용
- z-score 정규화 적용
- 모든 변수 스케일 통일

### 2. 처리 순서 고정

모든 전처리 과정을 고정된 순서로 수행하도록 설계했습니다.

1. 결측값 처리
2. 로그 변환
3. 정규화
4. 특징 준비
5. 모델 학습
6. 평가

### 3. 평가 기준 통일

- Stratified 10-fold 교차검증 적용
- 동일한 fold 분할 유지

---

##  재현성 관리

| 관리 항목 | 방법 |
|-----------|------|
| 처리 순서 | 고정 파이프라인 |
| 스케일링 | 표준 변환 적용 |
| 검증 방식 | 동일 fold 사용 |
| 실험 환경 | 문서화 |
| 결과 일관성 | 반복 실행 검증 |

반복 실행 시 동일한 결과가 도출되는 것을 확인했습니다.

---

##  결과

- 분류 정확도 약 **1% 향상**
- 한국정보과학회 2021 학술대회 **논문 게재**

본 프로젝트는 분석 이전 단계에서 데이터 처리 기준을 정의하는 것이 결과 신뢰도를 높인다는 점을 보여줍니다.
